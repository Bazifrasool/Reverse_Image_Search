{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues:\n",
    "**Ensure training directory has jpeg files only**\n",
    "**path enabled selection**\n",
    "**query pic dynamic**\n",
    "**number of results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_model = ResNet50(include_top=False,weights=\"imagenet\",pooling = \"avg\")\n",
    "import sys\n",
    "pathtodb=sys.argv[1]\n",
    "pathtoquery=sys.argv[2]\n",
    "number_of_results=int(sys.argv[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d_model.save(\"./resnet50.h5\")\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path_of_database = Path(pathtodb)\n",
    "Path_of_query = str(Path(pathtoquery))\n",
    "features_of_database = \"feature_embeddings.h5\"\n",
    "filenames_of_database = \"data_set_names.csv\"\n",
    "batch_size = 1\n",
    "threads=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model=keras.models.load_model(\"./resnet50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "list_of_files = os.listdir(Path_of_database)\n",
    "list_of_files = [ i for i in list_of_files if \".jpg\" in i]\n",
    "n_files=len(list_of_files)\n",
    "#print(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "file = h5py.File(features_of_database, \"w\")    \n",
    "feature_emb = file.create_dataset(\"features\", (len(list_of_files),2048), h5py.h5t.IEEE_F32LE,compression=\"lzf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def pre_proc(img):\n",
    "    return cv2.resize(img,(256,256))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_matr = [x for x in range(0,n_files)]\n",
    "def batch_preprocess(i):\n",
    "    matrix = cv2.imread(str(Path_of_database / list_of_files[i]))\n",
    "    matrix = pre_proc(matrix)\n",
    "    #print(\"that\",matrix)\n",
    "    global batch_matr\n",
    "    batch_matr[i]=matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "def parallel_read(begin,end):\n",
    "    with ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
    "        for i in range(begin,end+1):\n",
    "            executor.submit(batch_preprocess,(i))\n",
    "    return np.array(batch_matr[begin:end+1],dtype='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(beg,end):\n",
    "    if end>n_files:\n",
    "        end=n_files-1\n",
    "    batch_value=parallel_read(beg,end)\n",
    "    return batch_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_i in tqdm(range(0,n_files//batch_size,batch_size)):\n",
    "    batch=read_data(index_i,index_i+batch_size-1)\n",
    "    res=model.predict(batch)\n",
    "    for i,each in enumerate(res):\n",
    "        feature_emb[index_i+i,...]=each\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_filename(l_o_f):\n",
    "    with open(filenames_of_database,\"w+\") as f:\n",
    "        for i,each in enumerate(l_o_f):\n",
    "            f.write(str(each)+\",\"+str(i)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_filename(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_filenames = pd.read_csv(filenames_of_database,header=None)\n",
    "#print(dataset_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_pic(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = pre_proc(img)\n",
    "    return (model.predict(img[None,...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "def calculate_distances(n):\n",
    "    vector=query_pic(Path_of_query)\n",
    "    ld = h5py.File(features_of_database,\"r\")\n",
    "    values = []\n",
    "    for each in ld[\"features\"]:\n",
    "        values.append((1-distance.cosine(each,vector)))\n",
    "    from operator import itemgetter\n",
    "    from heapq import nlargest\n",
    "    return nlargest(n, enumerate(values), itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=calculate_distances(number_of_results)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 1\n",
    "rows = 6\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    img=plt.imread(str(Path_of_database / dataset_filenames.loc[results[i-1][0]][0]))\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
